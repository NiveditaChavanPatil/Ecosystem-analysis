# -*- coding: utf-8 -*-
"""autolysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DZptM43msYDTgXQIVAdpkruUJPP3Bmxe
"""

# Install necessary libraries
!pip install openai pandas matplotlib seaborn

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import openai

# Set up OpenAI API token from environment variable
openai.api_key = os.environ.get("AIPROXY_TOKEN")

def analyze_data(csv_file):
    # Read the dataset
    df = pd.read_csv(csv_file)

    # Summary statistics
    summary = df.describe()
    missing_values = df.isnull().sum()

    # Basic info
    data_info = df.info()

    # Output to check
    return df, summary, missing_values, data_info

# Install necessary libraries
!pip install openai pandas matplotlib seaborn

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import openai

# Set up OpenAI API token from environment variable
openai.api_key = os.environ.get("AIPROXY_TOKEN")

def analyze_data(csv_file):
    # Read the dataset
    df = pd.read_csv(csv_file)

    # Summary statistics
    summary = df.describe()
    missing_values = df.isnull().sum()

    # Basic info
    data_info = df.info()

    # Output to check
    return df, summary, missing_values, data_info

def create_visualizations(df):
    # Plotting a correlation heatmap if numerical data exists
    if df.select_dtypes(include=['number']).shape[1] > 1:
        corr_matrix = df.corr()
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
        plt.title('Correlation Matrix')
        plt.savefig("correlation_matrix.png")
        plt.close()

    # Save histograms for each numerical column
    for column in df.select_dtypes(include=['number']).columns:
        plt.figure(figsize=(8, 6))
        sns.histplot(df[column], kde=True)
        plt.title(f'Distribution of {column}')
        plt.savefig(f"{column}_distribution.png")
        plt.close()

def generate_story(summary, missing_values, corr_matrix):
    prompt = f"""
    I have a dataset with the following summary:
    {summary}

    The missing values are:
    {missing_values}

    The correlation matrix is:
    {corr_matrix}

    Based on this, write a narrative explaining the data, insights, and potential actions.
    """

    # Request the LLM for a summary story
    response = openai.Completion.create(
        model="gpt-4o-mini",
        prompt=prompt,
        max_tokens=500
    )

    return response.choices[0].text.strip()

def main(csv_file):
    # Analyze the dataset
    df, summary, missing_values, data_info = analyze_data(csv_file)

    # Create visualizations
    create_visualizations(df)

    # Generate the story using LLM
    story = generate_story(summary, missing_values, df.corr())

    # Write the story to README.md
    with open('README.md', 'w') as f:
        f.write("# Automated Data Analysis Report\n")
        f.write("### Data Overview\n")
        f.write(str(data_info))
        f.write("\n\n### Summary Statistics\n")
        f.write(str(summary))
        f.write("\n\n### Missing Values\n")
        f.write(str(missing_values))
        f.write("\n\n### Correlation Matrix\n")
        f.write(str(df.corr()))
        f.write("\n\n### Narrative\n")
        f.write(story)

    print("Analysis complete. Files generated: README.md")

# Run the main function on your dataset
main('goodreads.csv')  # Make sure this is the correct path

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Load the dataset
df = pd.read_csv('goodreads.csv')

# Check if there are any non-numeric entries in the 'rating' column
non_numeric_ratings = df[~df['rating'].apply(pd.to_numeric, errors='coerce').notnull()]

# Print out the rows with invalid ratings to inspect them
print("Rows with invalid ratings:\n", non_numeric_ratings)

# Now, force the 'rating' column to be numeric, invalid entries will be converted to NaN
df['rating'] = pd.to_numeric(df['rating'], errors='coerce')

# Check for missing values after conversion
missing_values = df.isnull().sum()

# Remove rows with missing values in 'rating' column
df = df.dropna(subset=['rating'])

# After cleaning, check the dataset info
print(f"Cleaned Dataset info:\n{df.info()}")

# Now try running the main function again
try:
    main('goodreads.csv')
except Exception as e:
    print(f"Error: {e}")

# Get a summary of the dataset
print(df.describe())

# Get the count of each genre
print(df['genre'].value_counts())

import matplotlib.pyplot as plt

# Plot histogram of ratings
plt.figure(figsize=(10, 6))
plt.hist(df['rating'], bins=10, edgecolor='black')
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.show()

import seaborn as sns

# Plot genre distribution
plt.figure(figsize=(10, 6))
sns.countplot(x='genre', data=df, palette='viridis')
plt.title('Distribution of Genres')
plt.xlabel('Genre')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

# Calculate average rating per genre
avg_rating_genre = df.groupby('genre')['rating'].mean().sort_values(ascending=False)

# Plot average rating by genre
plt.figure(figsize=(10, 6))
avg_rating_genre.plot(kind='bar', color='skyblue')
plt.title('Average Rating by Genre')
plt.xlabel('Genre')
plt.ylabel('Average Rating')
plt.xticks(rotation=45)
plt.show()

# Top 5 books by rating
top_books = df.nlargest(5, 'rating')
print(top_books[['title', 'author', 'rating']])

# Correlation matrix only for numeric columns
correlation_matrix = df.select_dtypes(include=['float64']).corr()

# Display the correlation matrix
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix (Numeric Only)')
plt.show()

